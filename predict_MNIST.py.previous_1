import os
import torch
import numpy as np
from PIL import Image
from torchvision import datasets
from transformers import MllamaForConditionalGeneration, AutoProcessor
from huggingface_hub import login
import re

# Path configurations
BASE_PATH = "/users/aczd097"
ARCHIVE_PATH = os.path.join(BASE_PATH, "archive")
MNIST_PATH = os.path.join(ARCHIVE_PATH, "mnist")
RESULTS_PATH = os.path.join(MNIST_PATH, "results")
RAW_PATH = os.path.join(MNIST_PATH, "raw")

# Create necessary directories
for path in [MNIST_PATH, RESULTS_PATH, RAW_PATH]:
    os.makedirs(path, exist_ok=True)

def setup_model():
    """Initialize and return the model and processor."""
    hf_token = os.getenv("HUGGINGFACE_API_KEY")
    if not hf_token:
        raise ValueError("Please set the HUGGINGFACE_API_KEY environment variable")
    
    login(token=hf_token)
    model_id = "meta-llama/Llama-3.2-11B-Vision-Instruct"
    
    print("Loading model and processor...")
    model = MllamaForConditionalGeneration.from_pretrained(
        model_id,
        torch_dtype=torch.bfloat16,
        device_map="auto",
        token=hf_token,
        local_files_only=True
    )
    
    processor = AutoProcessor.from_pretrained(
        model_id,
        token=hf_token,
        local_files_only=True
    )
    
    return model, processor

def load_mnist():
    """Load MNIST training and testing datasets."""
    print("Loading MNIST datasets...")
    train_dataset = datasets.MNIST(RAW_PATH, train=True, download=True)
    test_dataset = datasets.MNIST(RAW_PATH, train=False, download=True)
    return train_dataset, test_dataset

def extract_digit(response):
    """Extract digit from model response."""
    try:
        # Look for digit between answer tags
        match = re.search(r'<answer>(\d)</answer>', response)
        if match:
            return int(match.group(1))
        # If no valid digit found between tags, return 10 (error)
        return 10
    except:
        return 10

def process_dataset(dataset, model, processor, set_type):
    """Process either training or testing dataset."""
    true_labels = []
    predicted_labels = []
    total_images = len(dataset)
    
    print(f"Processing {set_type} dataset ({total_images} images)...")
    
    for idx in range(total_images):
        if idx % 100 == 0:
            print(f"Processing image {idx}/{total_images}")
            
        image, label = dataset[idx]
        # Convert to RGB as model expects color images
        image = image.convert('RGB')
        
        messages = [
            {"role": "user", "content": [
                {"type": "image"},
                {"type": "text", "text": "What digit (0-9) is shown in this image? Provide your answer in <answer> tags."}
            ]}
        ]
        
        try:
            input_text = processor.apply_chat_template(messages, add_generation_prompt=True)
            inputs = processor(
                image,
                input_text,
                add_special_tokens=False,
                return_tensors="pt"
            ).to(model.device)
            
            output = model.generate(**inputs, max_new_tokens=30)
            response = processor.decode(output[0])
            
            predicted_digit = extract_digit(response)
            
            true_labels.append(label)
            predicted_labels.append(predicted_digit)
            
        except Exception as e:
            print(f"Error processing image {idx}: {str(e)}")
            true_labels.append(label)
            predicted_labels.append(10)  # Error case
            
        # Save results periodically
        if idx % 1000 == 0:
            np.save(
                os.path.join(RESULTS_PATH, f'mnist_{set_type}_iteration_Llama-3.2-11B-Vision-Instruct.npy'),
                {'true_labels': true_labels, 'predicted_labels': predicted_labels}
            )
    
    # Save final results
    np.save(
        os.path.join(RESULTS_PATH, f'mnist_{set_type}_iteration_Llama-3.2-11B-Vision-Instruct.npy'),
        {'true_labels': true_labels, 'predicted_labels': predicted_labels}
    )
    
    return true_labels, predicted_labels

def main():
    # Setup model and processor
    model, processor = setup_model()
    
    # Load datasets
    train_dataset, test_dataset = load_mnist()
    
    # Process training dataset
    train_true, train_pred = process_dataset(train_dataset, model, processor, 'training')
    
    # Process testing dataset
    test_true, test_pred = process_dataset(test_dataset, model, processor, 'testing')
    
    # Print basic statistics
    print("\nProcessing complete!")
    print(f"Training accuracy: {sum(np.array(train_true) == np.array(train_pred)) / len(train_true):.4f}")
    print(f"Testing accuracy: {sum(np.array(test_true) == np.array(test_pred)) / len(test_true):.4f}")

if __name__ == "__main__":
    main()
